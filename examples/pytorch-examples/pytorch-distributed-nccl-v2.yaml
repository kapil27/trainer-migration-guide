# TrainJob v2 equivalent of pytorch-distributed-nccl v1 PyTorchJob
apiVersion: trainer.kubeflow.org/v1alpha1
kind: TrainJob
metadata:
  name: pytorch-distributed-nccl-v2
  namespace: opendatahub
spec:
  runtimeRef:
    name: torch-distributed
  trainer:
    numNodes: 4  # 1 master + 3 workers = 4 total nodes
    image: docker.io/kubeflowkatib/pytorch-mnist:v1beta1-45c5727
    command:
      - "python3"
      - "/opt/pytorch-mnist/mnist.py"
      - "--epochs=2"
      - "--backend=nccl"
    resourcesPerNode:
      requests:
        cpu: 500m
        memory: 512Mi
      limits:
        cpu: 1
        memory: 1Gi
